<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Basics of programming Apache Spark | Crash Course on Apache Spark</title>

    <!-- Styles and fonts -->
    <link href="themes/glide/stylesheets/glide.css" rel="stylesheet" type="text/css" />
    <link href="themes/glide/stylesheets/syntax.css" rel="stylesheet" type="text/css" />
    <link href='//fonts.googleapis.com/css?family=Bree+Serif&subset=latin,latin-ext' rel='stylesheet' type='text/css'>

    <!-- Place favicon.ico and apple-touch-icon.png in the root directory -->

    <script src="themes/glide/javascripts/modernizr.js" type="text/javascript"></script>
  </head>

  <body class="x010-basics-of-programming-apache-spark glide">
    <div class="page-wrapper">

      <!--[if lt IE 7]>
          <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
      <![endif]-->

      <header class="page-header" role="banner">
<a class="invisilink" href="./">            <span class="book-title">Crash Course on Apache Spark</span>
</a>        <span class="book-author visuallyhidden">by <a href="http://linkedin.com/in/saptak">Saptak Sen</a></span>
      </header>

        <div class="content-wrapper clearfix">

          <section class="main-content" role="main">
            <div class="main-content-source">
              <h1>Basics of programming Apache Spark</h1>

<h3>Concepts</h3>

<p><strong>RDD</strong> or Resilient Distributed Dataset is an immutable collection of objects that is usually partitioned and distributed across multiple physical nodes of the YARN cluster. So once a RDD is instantiated, it cannot be changed.</p>

<p>Typically, RDDs are instantiated by loading data from HDFS, HBASE, etc on a YARN cluster.</p>

<p>Once a RDD is instantiated you can apply a series of operations.  All operations fall into one of two types, <strong>transformations</strong> or <strong>actions</strong>. <strong>Transformation</strong> operations build out the processing graph which can then be applied on the partitioned dataset across the YARN cluster once the <strong>Action</strong> operation is invoked. Each transformation creates a new RDD.</p>

<p>Let&rsquo;s try it out.</p>

<h3>Hands-On</h3>

<p>Let&rsquo;s open a shell to our Sandbox through SSH:</p>

<p><img src="https://www.dropbox.com/s/tzsxvsnxfo26jn7/Screenshot_2015-04-13_07_58_43.png?dl=1" /></p>

<p>The default password is <code>hadoop</code> or in case of Sandbox on Azure, what ever you&rsquo;ve set it to.</p>

<p>Then let&rsquo;s get some data with the command below in your shell prompt:</p>
<pre class="highlight shell">wget http://en.wikipedia.org/wiki/Hortonworks
</pre>

<p><img src="https://www.dropbox.com/s/p6v9f2garljdpoj/Screenshot_2015-04-13_08_11_41.png?dl=1" /></p>

<p>Copy the data over to HDFS on Sandbox:</p>
<pre class="highlight shell">hadoop fs -put ~/Hortonworks /user/guest/Hortonworks
</pre>

<p>Let&rsquo;s start the PySpark shell and work through a simple example of counting the lines in a file. PySpark shell let&rsquo;s us interact with out data using Spark and Python:</p>
<pre class="highlight shell">pyspark
</pre>

<p><img src="https://www.dropbox.com/s/vr5syq682z8usla/Screenshot%202015-04-13%2007.59.59.png?dl=1" /></p>

<p>In case you do not want such verbose logging, you can change the verbosity in the <code>$SPARK_HOME/conf/log4j.properties</code> file.</p>

<p>First exit <code>pyspark</code> console by pressing <code>CTRL+D</code>.</p>

<p><img src="https://www.dropbox.com/s/wkxkddlkwuv94sb/Screenshot%202015-06-08%2007.16.04.png?dl=1" /></p>

<p>In case you do not already have the <code>log4j.properties</code> file, make a copy of the file using the command below</p>
<pre class="highlight plaintext">cp /usr/hdp/current/spark-client/conf/log4j.properties.template /usr/hdp/current/spark-client/conf/log4j.properties
</pre>

<p><img src="https://www.dropbox.com/s/dzvu6xu0yfb8bcy/Screenshot%202015-06-08%2007.09.28.png?dl=1" /></p>

<p>Then edit the file <code>/usr/hdp/current/spark-client/conf/log4j.properties</code> to change the line</p>
<pre class="highlight plaintext">log4j.rootCategory=INFO, console
</pre>

<p>to</p>
<pre class="highlight plaintext">log4j.rootCategory=WARN, console
</pre>

<p><img src="https://www.dropbox.com/s/x5z0wxkljwk1khb/Screenshot%202015-06-08%2007.17.29.png?dl=1" /></p>

<p>Now relaunch <code>pyspark</code></p>

<p><img src="https://www.dropbox.com/s/vjayu75m5g6n2db/Screenshot%202015-06-08%2007.19.16.png?dl=1" /></p>

<p>Now it&rsquo;s much cleaner. Let&rsquo;s start programming Spark.</p>

<p>As discussed above, the first step is to instantiate the RDD using the Spark Context <code>sc</code> with the file <code>Hortonworks</code> on HDFS.</p>
<pre class="highlight python"><span class="n">myLines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">'hdfs://sandbox.hortonworks.com/user/guest/Hortonworks'</span><span class="p">)</span>
</pre>

<p><img src="https://www.dropbox.com/s/a2d7v61acgozid7/Screenshot%202015-04-13%2009.10.32.png?dl=1" /></p>

<p>Now that we have instantiated the RDD, it&rsquo;s time to apply some transformation operations on the RDD. In this case, I am going to apply a simple transformation operation <code>filter(f)</code> using a Python lambda expression to filter out all the empty lines. The <code>filter(f)</code> method is a data-parallel operation that creates a new RDD from the input RDD by applying filter function <code>f</code> to each item in the parent RDD and only passing those elements where the filter function returns <code>True</code>. Elements that do not return <code>True</code> will be dropped. Like map(), filter can be applied individually to each entry in the dataset, so is easily parallelized using Spark.</p>
<pre class="highlight python"><span class="n">myLines_filtered</span> <span class="o">=</span> <span class="n">myLines</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">)</span>
</pre>

<p><img src="https://www.dropbox.com/s/0m0wg35a89p3rrj/Screenshot%202015-04-13%2009.17.52.png?dl=1" /></p>

<p>Note that the previous Python statement returned without any output. This lack of output signifies, that the transformation operation did not touch the data in any way so far, but has only modified the processing graph.</p>

<p>Let&rsquo;s make this transformation real, with an Action operation like &lsquo;count()&rsquo;, which will execute all the transformation actions before and apply this aggregate function.</p>
<pre class="highlight python"><span class="n">myLines_filtered</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre>

<p><img src="https://www.dropbox.com/s/q42679pbo8m2hf1/Screenshot%202015-04-13%2009.19.07.png?dl=1" /></p>

<p>The final result of this little Spark Job is the number you see at the end. In this case it is <code>341</code>.</p>

<p>Hope this little example whets up your appetite for more ambitious data science projects on the Hortonworks Data Platform.</p>

            </div>
            <nav class="main-content-nav clearfix" role="navigation">
              <ul>
                <li><a class="previous" href="007-Installing-Spark-1-2.html">Previous</a></li>
                <li><a class="next" href="013-scala-primer.html">Next</a></li>
              </ul>
            </nav>
          </section>

          <aside class="aside-content" role="complementary">
            <div class="aside-wrapper">

              <div class="block table-of-contents">
                <h3>Table of Contents</h3>
                <nav role="navigation">
                  <ul>
                    <li class='child '><a href="./">Introduction</a></li><li class='child '><a href="001-configuring-hortonwork-sandbox-azure.html">Configuring Hortonworks Sandbox on Azure</a></li><li class='child '><a href="004-installing-apache-spark-1-3-1.html">Installing Apache Spark 1.3.1 on HDP 2.2.4.2</a></li><li class='child '><a href="007-Installing-Spark-1-2.html">Installing Apache Spark 1.2.0 on HDP 2.2</a></li><li class='child active'><a href="010-basics-of-programming-apache-spark.html">Basics of programming Apache Spark</a></li><li class='child '><a href="013-scala-primer.html">A short primer on Scala</a></li><li class='child '><a href="016-spark-with-scala.html">Exploring Spark with Scala</a></li><li class='child '><a href="019-hive-orc-spark.html">Using Hive and ORC with Apache Spark</a></li><li class='child '><a href="022-installing-zeppelin.html">Installing and configuring Zeppelin</a></li><li class='child '><a href="025-ipython-notebook-with-apache-spark.html">Using IPython Notebook with Apache Spark</a></li><li class='child '><a href="028-spark-with-hdp.html">A Lap around Apache Spark 1.3.1 with HDP 2.3</a></li>
                  </ul>
                </nav>
              </div>
              <!--
              <div class="block translations">
                <h3>Book translations</h3>
                <p>This book is translated into 
                  <a href="#">Spanish</a>
                  and <a href="#">English</a>.
                  You can help with more translations <a href="https://github.com/saptak/spark">on Github</a>.
                </p>
              </div>
              -->
            </div><!-- end aside-wrapper -->
          </aside>

        </div><!-- end content-wrapper -->

      <footer class="page-footer">

        <div class="footer-wrapper">
          <!--
          <div class="block downloads">&nbsp;
            <h3>Downloads</h3>
            <p>Download this book in
                <a href="#">PDF</a>, <a href="#">mobi</a>, and <a href="#">epub</a>
              form for free.
            </p>
          </div>
          -->
          <div class="block license">
            <h3>License</h3>
            <p>This book is licensed under the <a href="https://creativecommons.org/licenses/by-sa/4.0">Attribution-ShareAlike</a> license.</p>
          </div>

          <div class="block open-source">
            <h3>This book is open source</h3>
            <p>The source of this book is <a href="https://github.com/saptak/spark">hosted on Github</a>. Go, ahead. Check it out.</p>
          </div>

          <small class="small-text">Made with <a href="http://bitbooks.cc">Bitbooks</a></small>

        </div><!-- end footer-wrapper -->

      </footer>


    </div><!-- end page-wrapper -->

    <!-- include scripts just before the close of the body tag -->
    <script src="themes/glide/javascripts/anchor.min.js" type="text/javascript"></script>
    <script src="themes/glide/javascripts/glide.js" type="text/javascript"></script>
  </body>
</html>